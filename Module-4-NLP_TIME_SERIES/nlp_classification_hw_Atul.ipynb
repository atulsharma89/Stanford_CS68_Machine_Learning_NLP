{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_classification_hw Atul.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGNl7QPn3JOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4e0a297e-13a9-4c49-c1c2-4c6c81e28029"
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "import nltk\n",
        "import re \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ4MDjkv4R1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e5e49224-b283-40a1-b8c8-3f73ca732196"
      },
      "source": [
        "#the homework is to build a classifier to predict whether a customer will recommend a product based on the review text they have filled in.\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/cjflanagan/cs68/master/Womens%20Clothing%20E-Commerce%20Reviews%20-%20Womens%20Clothing%20E-Commerce%20Reviews.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>1</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>1</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>1</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age                    Title  ... Department Name  Class Name\n",
              "0   33                      NaN  ...        Intimate   Intimates\n",
              "1   34                      NaN  ...         Dresses     Dresses\n",
              "2   60  Some major design flaws  ...         Dresses     Dresses\n",
              "3   50         My favorite buy!  ...         Bottoms       Pants\n",
              "4   47         Flattering shirt  ...            Tops     Blouses\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJCx30hXVQy8",
        "colab_type": "text"
      },
      "source": [
        "The homework is to use the Review Text (and any other feature's you'd like) to predict whether someone will recommend (Recommended IND) a product or not.\n",
        "\n",
        "# Have fun!\n",
        "\n",
        "You are also welcome to use AutoML if you'd prefer (or both! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9GWxH18UzAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lets create a \n",
        "data = data[['Review Text','Recommended IND']]\n",
        "data.columns = ['Text','Recommend']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtdqTm6oM2ol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "412cd91b-732c-42d3-d2d8-2765f61fe9d5"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Recommend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Recommend\n",
              "0  Absolutely wonderful - silky and sexy and comf...          1\n",
              "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
              "2  I had such high hopes for this dress and reall...          0\n",
              "3  I love, love, love this jumpsuit. it's fun, fl...          1\n",
              "4  This shirt is very flattering to all due to th...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXM-M2GTM2TJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9a409fe1-63fb-4692-c480-6d20c25014a7"
      },
      "source": [
        "# Inspecting the variables\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23486 entries, 0 to 23485\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Text       22641 non-null  object\n",
            " 1   Recommend  23486 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 367.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceTFPH0B5xCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing blank variables with 'unknown' ready for processing\n",
        "data['Text'].fillna('unknown', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Ac46NKU1-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "1ad33415-568b-4a09-cc44-55dff91c5c18"
      },
      "source": [
        "## Lenght of the Text using KDEplot\n",
        "lenght = data[\"Text\"].str.len()\n",
        "sns.distplot(lenght)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZALRvpw5qcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "faf4ef47-c633-48fb-c4ed-908fe3fdebff"
      },
      "source": [
        "## Checking for stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stopwordSet = set(stopwords.words(\"english\"))\n",
        "stopwordSet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQPkdzX-kP-g",
        "colab_type": "text"
      },
      "source": [
        "### Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEZgVpNfkJcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## NlP Processing\n",
        "ps = PorterStemmer()\n",
        "lemma = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE94vC-LkT4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "781e93af-a10b-43d6-cd25-82a2f4742db6"
      },
      "source": [
        "print(ps.stem('rocks'))\n",
        "print(ps.stem('nonwords'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rock\n",
            "nonword\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7OFks4AkWBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d21c16e7-329d-4ef8-b525-28c8105eedca"
      },
      "source": [
        "print(lemma.lemmatize('rocks'))\n",
        "print(lemma.lemmatize('nonwords'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rock\n",
            "nonwords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xh5cRUJkYrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "df61838b-50ef-47bb-e3ba-fabaa79996f9"
      },
      "source": [
        "data[\"Text\"].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Absolutely wonderful - silky and sexy and comf...\n",
              "1    Love this dress!  it's sooo pretty.  i happene...\n",
              "2    I had such high hopes for this dress and reall...\n",
              "3    I love, love, love this jumpsuit. it's fun, fl...\n",
              "4    This shirt is very flattering to all due to th...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz3C8QZvum31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Regex few details\n",
        "#What does this regex match: [^a-z]?\n",
        "\n",
        "#The first character — [ — marks the beginning of a character range. This is ended by the ].\n",
        "\n",
        "#The next character — ^ — means that the character range is negated, that is, it will only match something not in the range.\n",
        "\n",
        "#The next three characters — a-z — represent all characters from a to z, ie abcdef...z, the lowercase alphabetic characters.\n",
        "\n",
        "#Therefore, this regex matches any character which is not a lowercase alphabetic character."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvcSGMhgkoik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Clean the text \n",
        "text_reviews = list()\n",
        "for sentence in data.Text:\n",
        "    text = re.sub('[^a-zA-Z]',\" \", sentence)\n",
        "    ## Remove punctuation\n",
        "    text = re.sub('[^\\w\\s]', \" \", sentence)\n",
        "    ## Remove numbers\n",
        "    #text = text.str.replace('\\d+', '')\n",
        "    text=re.sub('\\d+', \" \", sentence)\n",
        "    ## Remove special characters\n",
        "    #text = text.apply(lambda x: ([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
        "    #text = text.apply(lambda x: \"\".join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
        "    ## Remove whitespaces\n",
        "    #text = text.apply(lambda x: (x.strip() for x in x.split()))\n",
        "    #text = text.apply(lambda x: \" \".join(x.strip() for x in x.split()))\n",
        "    #print(sentence)\n",
        "    #print(text, '\\n')\n",
        "    text = text.lower()\n",
        "    text = word_tokenize(text, language=\"english\")\n",
        "    text = [lemma.lemmatize(word) for word in text if(word) not in stopwordSet]\n",
        "    text = \" \".join(text)\n",
        "    text_reviews.append(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2s4PS2liuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create the (B.O.W) bag of word model\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "X = cv.fit_transform(text_reviews).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWElEFJ8mCSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "dad872d9-8b60-422a-e474-6b461b892480"
      },
      "source": [
        "pd.DataFrame(X, columns=cv.get_feature_names()).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>accent</th>\n",
              "      <th>accentuates</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accommodate</th>\n",
              "      <th>accurate</th>\n",
              "      <th>across</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>add</th>\n",
              "      <th>added</th>\n",
              "      <th>adding</th>\n",
              "      <th>addition</th>\n",
              "      <th>additional</th>\n",
              "      <th>adjust</th>\n",
              "      <th>adjustable</th>\n",
              "      <th>adorable</th>\n",
              "      <th>adore</th>\n",
              "      <th>advice</th>\n",
              "      <th>afraid</th>\n",
              "      <th>ag</th>\n",
              "      <th>age</th>\n",
              "      <th>ago</th>\n",
              "      <th>agree</th>\n",
              "      <th>ahead</th>\n",
              "      <th>air</th>\n",
              "      <th>airy</th>\n",
              "      <th>ala</th>\n",
              "      <th>allow</th>\n",
              "      <th>allows</th>\n",
              "      <th>almost</th>\n",
              "      <th>alone</th>\n",
              "      <th>along</th>\n",
              "      <th>already</th>\n",
              "      <th>also</th>\n",
              "      <th>alteration</th>\n",
              "      <th>altered</th>\n",
              "      <th>alternative</th>\n",
              "      <th>although</th>\n",
              "      <th>...</th>\n",
              "      <th>wonderful</th>\n",
              "      <th>wonderfully</th>\n",
              "      <th>wool</th>\n",
              "      <th>word</th>\n",
              "      <th>wore</th>\n",
              "      <th>work</th>\n",
              "      <th>worked</th>\n",
              "      <th>working</th>\n",
              "      <th>worn</th>\n",
              "      <th>worried</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worth</th>\n",
              "      <th>would</th>\n",
              "      <th>woven</th>\n",
              "      <th>wow</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrinkle</th>\n",
              "      <th>wrinkled</th>\n",
              "      <th>wrist</th>\n",
              "      <th>write</th>\n",
              "      <th>wrong</th>\n",
              "      <th>xl</th>\n",
              "      <th>xs</th>\n",
              "      <th>xsmall</th>\n",
              "      <th>xsp</th>\n",
              "      <th>xx</th>\n",
              "      <th>xxsp</th>\n",
              "      <th>yarn</th>\n",
              "      <th>year</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yet</th>\n",
              "      <th>yoga</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipped</th>\n",
              "      <th>zipper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   able  absolutely  accent  accentuates  ...  younger  zip  zipped  zipper\n",
              "0     0           1       0            0  ...        0    0       0       0\n",
              "1     0           0       0            0  ...        0    0       0       0\n",
              "2     0           0       0            0  ...        0    1       0       1\n",
              "3     0           0       0            0  ...        0    0       0       0\n",
              "4     0           0       0            0  ...        0    0       0       0\n",
              "\n",
              "[5 rows x 1500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXB14V-amFs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y= data['Recommend']\n",
        "\n",
        "## Split the dataset into Training and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state = 0)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train , test_size=0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7thTclE-mVCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "84b10190-be7f-49ce-ac99-2a5ad5ef4e40"
      },
      "source": [
        "## Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "Y_pred = logreg.predict(X_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upohz91AmYrd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3862e34c-1da5-4acf-9957-5c29311ceb3a"
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(y_valid, Y_pred)\n",
        "print('AUC: ', metrics.auc(fpr, tpr))\n",
        "print(classification_report(y_valid, Y_pred))\n",
        "print(confusion_matrix(y_valid, Y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.7587346484971108\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.57      0.63       671\n",
            "           1       0.91      0.95      0.93      3087\n",
            "\n",
            "    accuracy                           0.88      3758\n",
            "   macro avg       0.81      0.76      0.78      3758\n",
            "weighted avg       0.87      0.88      0.88      3758\n",
            "\n",
            "[[ 382  289]\n",
            " [ 160 2927]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvV6XQgULnCG",
        "colab_type": "text"
      },
      "source": [
        "**There are four ways to check if the predictions are right or wrong:**\n",
        "\n",
        "TN / True Negative: the case was negative and predicted negative\n",
        "\n",
        "TP / True Positive: the case was positive and predicted positive\n",
        "\n",
        "FN / False Negative: the case was positive but predicted negative\n",
        "\n",
        "FP / False Positive: the case was negative but predicted positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxyaX6iVL-US",
        "colab_type": "text"
      },
      "source": [
        "Source: https://medium.com/@kohlishivam5522/understanding-a-classification-report-for-your-machine-learning-model-88815e2ce397\n",
        "\n",
        "**Precision** — What percent of your predictions were correct?\n",
        "Precision is the ability of a classifier not to label an instance positive that is actually negative. For each class, it is defined as the ratio of true positives to the sum of a true positive and false positive.\n",
        "\n",
        "Precision:- Accuracy of positive predictions.\n",
        "\n",
        "Precision = TP/(TP + FP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IDOSj_QMFnt",
        "colab_type": "text"
      },
      "source": [
        "Recall — What percent of the positive cases did you catch?\n",
        "\n",
        "Recall is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.\n",
        "\n",
        "Recall:- Fraction of positives that were correctly identified.\n",
        "\n",
        "Recall = TP/(TP+FN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBkKgiNpMNid",
        "colab_type": "text"
      },
      "source": [
        "**F1 score** — What percent of positive predictions were correct?\n",
        "The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
        "\n",
        "\n",
        "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UDHJj_DMZnN",
        "colab_type": "text"
      },
      "source": [
        "**Support**\n",
        "\n",
        "Support is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for stratified sampling or rebalancing. Support doesn’t change between models but instead diagnoses the evaluation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ir-Go0KjAS",
        "colab_type": "text"
      },
      "source": [
        "**Precision Score**\n",
        "\n",
        "\n",
        "TP – True Positives\n",
        "\n",
        "FP – False Positives\n",
        "\n",
        "\n",
        "Precision – Accuracy of positive predictions.\n",
        "\n",
        "Precision = TP/(TP + FP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlRWevjWJ-u5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66979682-5cc2-4051-ebb6-0d292b442da3"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(\"Precision score: {}\".format(precision_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.910136815920398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kA447ZjK301",
        "colab_type": "text"
      },
      "source": [
        "**Recall Score**\n",
        "\n",
        "\n",
        "FN – False Negatives\n",
        "\n",
        "Recall (aka sensitivity or true positive rate): Fraction of positives That were correctly identified.\n",
        "\n",
        "\n",
        "Recall = TP/(TP+FN)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMw71Ic6LJoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9273aa1-e524-4313-85fb-640d8cbccbdd"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"Recall score: {}\".format(recall_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall score: 0.9481697440881114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uee6-fFRLV9a",
        "colab_type": "text"
      },
      "source": [
        "**F1 Score**\n",
        "\n",
        "\n",
        "F1 Score (aka F-Score or F-Measure) – A helpful metric for comparing two classifiers. F1 Score takes into account precision and the recall. It is created by finding the the harmonic mean of precision and recall.\n",
        "\n",
        "\n",
        "F1 = 2 x (precision x recall)/(precision + recall)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH1yEQoDLb4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47f549ac-3f86-47bf-e40b-e3359271f18a"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"F1 Score: {}\".format(f1_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score: 0.9287640805965413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26r0e-cZmi6M",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxrgwQKMmdBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Random Forest\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(X_train, y_train)\n",
        "Y_pred = random_forest.predict(X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij9Je389moyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e2923c0f-e409-489f-96f1-913ee4fc00b7"
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(y_valid, Y_pred)\n",
        "print('AUC: ', metrics.auc(fpr, tpr))\n",
        "print(classification_report(y_valid, Y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.6520775793107676\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.32      0.46       671\n",
            "           1       0.87      0.99      0.92      3087\n",
            "\n",
            "    accuracy                           0.87      3758\n",
            "   macro avg       0.85      0.65      0.69      3758\n",
            "weighted avg       0.86      0.87      0.84      3758\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tqLDFGbmvGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "28cada2c-0df9-43d8-fa95-a2f84d3c2012"
      },
      "source": [
        "print(confusion_matrix(y_valid, Y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 213  458]\n",
            " [  41 3046]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du3sCtKjMuYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2b6da7c-f55f-407f-f0da-2e30571b4896"
      },
      "source": [
        "#precision score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(\"Precision score: {}\".format(precision_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.8692922374429224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA-b3_e8M0_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54858666-48ca-4e55-ad8d-6aafe51b5d67"
      },
      "source": [
        "#recall score\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"Recall score: {}\".format(recall_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall score: 0.9867184969225785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B56n7B0GzV2R",
        "colab_type": "text"
      },
      "source": [
        "### Naives baye multinomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGRcGfkNm0dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Naives baye multinomial\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "Y_pred = clf.predict(X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqh4sO--m7Gm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6bc6c727-470a-4ae1-9afe-29676171f886"
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(y_valid, Y_pred)\n",
        "print('AUC: ', metrics.auc(fpr, tpr))\n",
        "print(classification_report(y_valid, Y_pred))\n",
        "print(confusion_matrix(y_valid, Y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.822561272042704\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.73      0.69       671\n",
            "           1       0.94      0.91      0.93      3087\n",
            "\n",
            "    accuracy                           0.88      3758\n",
            "   macro avg       0.79      0.82      0.81      3758\n",
            "weighted avg       0.89      0.88      0.88      3758\n",
            "\n",
            "[[ 492  179]\n",
            " [ 272 2815]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbwiOkXJm9XM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b272c932-7b7a-48d8-d0ba-76d97d2cfbc3"
      },
      "source": [
        "print(confusion_matrix(y_valid, Y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 492  179]\n",
            " [ 272 2815]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ya_uAnNCaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc18a1eb-3bcc-4ce0-c0a4-d165d04c82c4"
      },
      "source": [
        "#precision score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(\"Precision score: {}\".format(precision_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.9402137608550434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLKxowRWNF2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1f454b0-0285-4214-b3cc-fac09b8ab9ac"
      },
      "source": [
        "#recall score\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"Recall score: {}\".format(recall_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall score: 0.9118885649497894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsUDlnrKnpPl",
        "colab_type": "text"
      },
      "source": [
        "### XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csX5w9EwnCn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "24de3520-62e8-4314-b1fc-0ae5ad8e59c2"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUfgH3NqoF-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions for test data\n",
        "#y_pred = model.predict(X_test)\n",
        "Y_pred = model.predict(X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20QqqkEvoUFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f57a380e-3cc0-4ff3-da59-f0a761903118"
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(y_valid, Y_pred)\n",
        "print('AUC: ', metrics.auc(fpr, tpr))\n",
        "print(classification_report(y_valid, Y_pred))\n",
        "print(confusion_matrix(y_valid, Y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.6180596289328306\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.25      0.38       671\n",
            "           1       0.86      0.99      0.92      3087\n",
            "\n",
            "    accuracy                           0.85      3758\n",
            "   macro avg       0.83      0.62      0.65      3758\n",
            "weighted avg       0.85      0.85      0.82      3758\n",
            "\n",
            "[[ 168  503]\n",
            " [  44 3043]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VbK4F44ogV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78fab673-c6c7-4da5-c1f3-41ce406ae88b"
      },
      "source": [
        "#precision score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(\"Precision score: {}\".format(precision_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.8581500282007897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_x_D0qyNihh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1565d1b4-ee5f-4817-e3c6-d9a3fa598373"
      },
      "source": [
        "#recall score\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"Recall score: {}\".format(recall_score(y_valid,Y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall score: 0.9857466796242307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_SFA_NTNlnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}